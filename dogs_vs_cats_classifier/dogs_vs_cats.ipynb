{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_DATA_DIRECTORY = '/home/xxx/workspace/dogs_vs_cats/data/train'\n",
    "VALIDATION_DATA_DIRECTORY = '/home/xxx/workspace/dogs_vs_cats/data/validation'\n",
    "TRAIN_SET_SIZE = 10000\n",
    "VALIDATION_SET_SIZE = 2000\n",
    "EPOCH = 50\n",
    "TRAIN_BATCH_SIZE = 50\n",
    "\n",
    "IMG_WIDTH = 250\n",
    "IMG_HEIGHT = 250\n",
    "NUM_CHANNELS = 3\n",
    "\n",
    "ACTIVATION_FUNCTION = 'relu'\n",
    "OUTPUT_ACTIVATION_FUNCTION = 'softmax'\n",
    "\n",
    "DROPOUT_KEEP_PROB = 0.4\n",
    "FILTER_COUNT = 64\n",
    "KERNEL_SIZE = (5,5)\n",
    "POOL_SIZE = (3,3)\n",
    "PADDING_OPTION='same'\n",
    "\n",
    "DENSE_DIMENSION = 128\n",
    "DENSE_DIMENSION_FLATTEN = 1\n",
    "\n",
    "MODEL_COMPILE_OPTIMIZER = optimizers.SGD(lr=1e-4, momentum=0.9)\n",
    "MODEL_COMPILE_LOSS = 'binary_crossentropy'\n",
    "MODEL_COMPILE_METRIC = 'accuracy'\n",
    "\n",
    "GENERATOR_CLASS_MODE = 'binary'\n",
    "GENERATOR_USE_SHUFFLE = True\n",
    "\n",
    "IMG_DATA_GENERATOR_RESCALE = 1. / 255\n",
    "IMG_DATA_GENERATOR_MOD_RANGE = 0.2\n",
    "\n",
    "MODEL_FILENAME = 'model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_shape = (IMG_WIDTH, IMG_HEIGHT, NUM_CHANNELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##########################################\n",
    "# https://keras.io/models/sequential/    #\n",
    "##########################################\n",
    "\n",
    "# Sequential model methods\n",
    "\n",
    "# compile\n",
    "\n",
    "# compile(self, optimizer, loss, metrics=None, sample_weight_mode=None)\n",
    "# Configures the learning process.\n",
    "\n",
    "# Arguments\n",
    "\n",
    "# optimizer: str (name of optimizer) or optimizer object. See optimizers.\n",
    "# loss: str (name of objective function) or objective function. See losses.\n",
    "# metrics: list of metrics to be evaluated by the model during training and testing. Typically you will use  metrics=['accuracy']. See metrics.\n",
    "# sample_weight_mode: if you need to do timestep-wise sample weighting (2D weights), set this to \"temporal\". \"None\" defaults to sample-wise weights (1D).\n",
    "# **kwargs: for Theano backend, these are passed into K.function. When using the Tensorflow backend, these are passed into tf.Session.run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##########################################\n",
    "# https://keras.io/layers/convolutional/ #\n",
    "##########################################\n",
    "\n",
    "# Conv2D\n",
    "\n",
    "# keras.layers.convolutional.Conv2D(filters, kernel_size, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1), activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None)\n",
    "# 2D convolution layer (e.g. spatial convolution over images).\n",
    "\n",
    "# This layer creates a convolution kernel that is convolved with the layer input to produce a tensor of outputs. If  use_bias is True, a bias vector is created and added to the outputs. Finally, if activation is not None, it is applied to the outputs as well.\n",
    "\n",
    "# When using this layer as the first layer in a model, provide the keyword argument input_shape (tuple of integers, does not include the sample axis), e.g. input_shape=(128, 128, 3) for 128x128 RGB pictures in  data_format=\"channels_last\".\n",
    "\n",
    "# Arguments\n",
    "\n",
    "# filters: Integer, the dimensionality of the output space (i.e. the number output of filters in the convolution).\n",
    "# kernel_size: An integer or tuple/list of 2 integers, specifying the width and height of the 2D convolution window. Can be a single integer to specify the same value for all spatial dimensions.\n",
    "# strides: An integer or tuple/list of 2 integers, specifying the strides of the convolution along the width and height. Can be a single integer to specify the same value for all spatial dimensions. Specifying any stride value != 1 is incompatible with specifying any dilation_rate value != 1.\n",
    "# padding: one of \"valid\" or \"same\" (case-insensitive).\n",
    "# data_format: A string, one of channels_last (default) or channels_first. The ordering of the dimensions in the inputs. channels_last corresponds to inputs with shape  (batch, height, width, channels) while channels_first corresponds to inputs with shape  (batch, channels, height, width). It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be \"channels_last\".\n",
    "# dilation_rate: an integer or tuple/list of 2 integers, specifying the dilation rate to use for dilated convolution. Can be a single integer to specify the same value for all spatial dimensions. Currently, specifying any dilation_rate value != 1 is incompatible with specifying any stride value != 1.\n",
    "# activation: Activation function to use (see activations). If you don't specify anything, no activation is applied (ie. \"linear\" activation: a(x) = x).\n",
    "# use_bias: Boolean, whether the layer uses a bias vector.\n",
    "# kernel_initializer: Initializer for the kernel weights matrix (see initializers).\n",
    "# bias_initializer: Initializer for the bias vector (see initializers).\n",
    "# kernel_regularizer: Regularizer function applied to the kernel weights matrix (see regularizer).\n",
    "# bias_regularizer: Regularizer function applied to the bias vector (see regularizer).\n",
    "# activity_regularizer: Regularizer function applied to the output of the layer (its \"activation\"). (see regularizer).\n",
    "# kernel_constraint: Constraint function applied to the kernel matrix (see constraints).\n",
    "# bias_constraint: Constraint function applied to the bias vector (see constraints)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##########################################\n",
    "# https://keras.io/layers/core/          #\n",
    "##########################################\n",
    "\n",
    "# Dense\n",
    "\n",
    "# keras.layers.core.Dense(units, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None)\n",
    "# Just your regular densely-connected NN layer.\n",
    "\n",
    "# Arguments\n",
    "\n",
    "# units: Positive integer, dimensionality of the output space.\n",
    "# activation: Activation function to use (see activations). If you don't specify anything, no activation is applied (ie. \"linear\" activation: a(x) = x).\n",
    "# use_bias: Boolean, whether the layer uses a bias vector.\n",
    "# kernel_initializer: Initializer for the kernel weights matrix (see initializers).\n",
    "# bias_initializer: Initializer for the bias vector (see initializers).\n",
    "# kernel_regularizer: Regularizer function applied to the kernel weights matrix (see regularizer).\n",
    "# bias_regularizer: Regularizer function applied to the bias vector (see regularizer).\n",
    "# activity_regularizer: Regularizer function applied to the output of the layer (its \"activation\"). (see regularizer).\n",
    "# kernel_constraint: Constraint function applied to the kernel weights matrix (see constraints).\n",
    "# bias_constraint: Constraint function applied to the bias vector (see constraints)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(FILTER_COUNT, KERNEL_SIZE, input_shape=input_shape, padding=PADDING_OPTION))\n",
    "model.add(Activation(ACTIVATION_FUNCTION))\n",
    "model.add(MaxPooling2D(pool_size=POOL_SIZE))\n",
    "\n",
    "model.add(Conv2D(FILTER_COUNT, KERNEL_SIZE))\n",
    "model.add(Activation(ACTIVATION_FUNCTION))\n",
    "model.add(MaxPooling2D(pool_size=POOL_SIZE))\n",
    "\n",
    "model.add(Conv2D(DENSE_DIMENSION, KERNEL_SIZE))\n",
    "model.add(Activation(ACTIVATION_FUNCTION))\n",
    "model.add(MaxPooling2D(pool_size=POOL_SIZE))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(DENSE_DIMENSION))\n",
    "model.add(Activation(ACTIVATION_FUNCTION))\n",
    "model.add(Dropout(DROPOUT_KEEP_PROB))\n",
    "model.add(Dense(DENSE_DIMENSION_FLATTEN))\n",
    "model.add(Activation(OUTPUT_ACTIVATION_FUNCTION))\n",
    "\n",
    "model.compile(loss=MODEL_COMPILE_LOSS,\n",
    "              optimizer=MODEL_COMPILE_OPTIMIZER,\n",
    "              metrics=[MODEL_COMPILE_METRIC])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##########################################\n",
    "# https://keras.io/models/sequential/    #\n",
    "##########################################\n",
    "\n",
    "# fit_generator\n",
    "\n",
    "# fit_generator(self, generator, steps_per_epoch, epochs=1, verbose=1, callbacks=None, validation_data=None, validation_steps=None, class_weight=None, max_queue_size=10, workers=1, use_multiprocessing=False, initial_epoch=0)\n",
    "# Fits the model on data generated batch-by-batch by a Python generator.\n",
    "\n",
    "# The generator is run in parallel to the model, for efficiency. For instance, this allows you to do real-time data augmentation on images on CPU in parallel to training your model on GPU.\n",
    "\n",
    "# Arguments\n",
    "\n",
    "# generator: A generator. The output of the generator must be either\n",
    "# a tuple (inputs, targets)\n",
    "# a tuple (inputs, targets, sample_weights). All arrays should contain the same number of samples. The generator is expected to loop over its data indefinitely. An epoch finishes when steps_per_epoch batches have been seen by the model.\n",
    "# steps_per_epoch: Total number of steps (batches of samples) to yield from generator before declaring one epoch finished and starting the next epoch. It should typically be equal to the number of unique samples of your dataset divided by the batch size.\n",
    "# epochs: Integer, total number of iterations on the data.\n",
    "# verbose: Verbosity mode, 0, 1, or 2.\n",
    "# callbacks: List of callbacks to be called during training.\n",
    "# validation_data: This can be either\n",
    "# A generator for the validation data\n",
    "# A tuple (inputs, targets)\n",
    "# A tuple (inputs, targets, sample_weights).\n",
    "# validation_steps: Only relevant if validation_data is a generator. Number of steps to yield from validation generator at the end of every epoch. It should typically be equal to the number of unique samples of your validation dataset divided by the batch size.\n",
    "# class_weight: Dictionary mapping class indices to a weight for the class.\n",
    "# max_queue_size: Maximum size for the generator queue\n",
    "# workers: Maximum number of processes to spin up\n",
    "# use_multiprocessing: Ff True, use process based threading. Note that because this implementation relies on multiprocessing, you should not pass non picklable arguments to the generator as they can't be passed easily to children processes.\n",
    "# initial_epoch: Epoch at which to start training (useful for resuming a previous training run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##########################################\n",
    "# https://keras.io/preprocessing/image/  #\n",
    "##########################################\n",
    "    \n",
    "# ImageDataGenerator\n",
    "\n",
    "# keras.preprocessing.image.ImageDataGenerator(featurewise_center=False,\n",
    "#     samplewise_center=False,\n",
    "#     featurewise_std_normalization=False,\n",
    "#     samplewise_std_normalization=False,\n",
    "#     zca_whitening=False,\n",
    "#     zca_epsilon=1e-6,\n",
    "#     rotation_range=0.,\n",
    "#     width_shift_range=0.,\n",
    "#     height_shift_range=0.,\n",
    "#     shear_range=0.,\n",
    "#     zoom_range=0.,\n",
    "#     channel_shift_range=0.,\n",
    "#     fill_mode='nearest',\n",
    "#     cval=0.,\n",
    "#     horizontal_flip=False,\n",
    "#     vertical_flip=False,\n",
    "#     rescale=None,\n",
    "#     preprocessing_function=None,\n",
    "#     data_format=K.image_data_format())\n",
    "# Generate batches of tensor image data with real-time data augmentation. The data will be looped over (in batches) indefinitely.\n",
    "\n",
    "# Arguments:\n",
    "\n",
    "# featurewise_center: Boolean. Set input mean to 0 over the dataset, feature-wise.\n",
    "# samplewise_center: Boolean. Set each sample mean to 0.\n",
    "# featurewise_std_normalization: Boolean. Divide inputs by std of the dataset, feature-wise.\n",
    "# samplewise_std_normalization: Boolean. Divide each input by its std.\n",
    "# zca_epsilon: epsilon for ZCA whitening. Default is 1e-6.\n",
    "# zca_whitening: Boolean. Apply ZCA whitening.\n",
    "# rotation_range: Int. Degree range for random rotations.\n",
    "# width_shift_range: Float (fraction of total width). Range for random horizontal shifts.\n",
    "# height_shift_range: Float (fraction of total height). Range for random vertical shifts.\n",
    "# shear_range: Float. Shear Intensity (Shear angle in counter-clockwise direction as radians)\n",
    "# zoom_range: Float or [lower, upper]. Range for random zoom. If a float,  [lower, upper] = [1-zoom_range, 1+zoom_range].\n",
    "# channel_shift_range: Float. Range for random channel shifts.\n",
    "# fill_mode: One of {\"constant\", \"nearest\", \"reflect\" or \"wrap\"}. Points outside the boundaries of the input are filled according to the given mode.\n",
    "# cval: Float or Int. Value used for points outside the boundaries when fill_mode = \"constant\".\n",
    "# horizontal_flip: Boolean. Randomly flip inputs horizontally.\n",
    "# vertical_flip: Boolean. Randomly flip inputs vertically.\n",
    "# rescale: rescaling factor. Defaults to None. If None or 0, no rescaling is applied, otherwise we multiply the data by the value provided (before applying any other transformation).\n",
    "# preprocessing_function: function that will be implied on each input. The function will run before any other modification on it. The function should take one argument: one image (Numpy tensor with rank 3), and should output a Numpy tensor with the same shape.\n",
    "# data_format: One of {\"channels_first\", \"channels_last\"}. \"channels_last\" mode means that the images should have shape  (samples, height, width, channels), \"channels_first\" mode means that the images should have shape  (samples, channels, height, width). It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be \"channels_last\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(\n",
    "    rescale=IMG_DATA_GENERATOR_RESCALE,\n",
    "    shear_range=IMG_DATA_GENERATOR_MOD_RANGE,\n",
    "    zoom_range=IMG_DATA_GENERATOR_MOD_RANGE)\n",
    "train_generator = train_gen.flow_from_directory(\n",
    "    TRAIN_DATA_DIRECTORY,\n",
    "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    "    shuffle=GENERATOR_USE_SHUFFLE,\n",
    "    class_mode=GENERATOR_CLASS_MODE)\n",
    "\n",
    "test_gen = ImageDataGenerator(rescale=IMG_DATA_GENERATOR_RESCALE)\n",
    "validation_generator = test_gen.flow_from_directory(\n",
    "    VALIDATION_DATA_DIRECTORY,\n",
    "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    "    shuffle=GENERATOR_USE_SHUFFLE,\n",
    "    class_mode=GENERATOR_CLASS_MODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=TRAIN_SET_SIZE // TRAIN_BATCH_SIZE,\n",
    "    epochs=EPOCH,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=VALIDATION_SET_SIZE // TRAIN_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.save_weights(MODEL_FILENAME)\n",
    "\n",
    "print(time.time() - start_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
